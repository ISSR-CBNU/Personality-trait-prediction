{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from typing import List, Tuple, Dict\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import datetime\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from VGG16 import VGG16\n",
    "from ResNet101 import ResNet101\n",
    "from Inception_V2 import Inception_V2\n",
    "from Inception_V2_LSTM import Inception_V2_LSTM\n",
    "from VGG16_LSTM import VGG16_LSTM\n",
    "from ResNet101_LSTM import ResNet101_LSTM\n",
    "from torchvision import transforms, utils, models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from facenet_pytorch import MTCNN\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "formatter = logging.Formatter('[%(asctime)s]::%(module)s::%(levelname)s::%(message)s')\n",
    "streamHandler = logging.StreamHandler()\n",
    "streamHandler.setFormatter(formatter)\n",
    "fileHandler = logging.FileHandler('./LOG/personalityLog.log')\n",
    "fileHandler.setFormatter(formatter)\n",
    "logger.addHandler(streamHandler)\n",
    "logger.addHandler(fileHandler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model_file_path = './save_model/{}_{}.{}'\n",
    "with open('/mnt/2ndSSD/FirstImpressions_V2/Preprocess_data/Visual/15Frames/Full_frames/train_set.dat', \"rb\") as training_file:\n",
    "    train_set_data = pickle.load(training_file)\n",
    "train_set_data=train_set_data[:3000]\n",
    "with open('/mnt/2ndSSD/FirstImpressions_V2/Preprocess_data/Visual/15Frames/Full_frames/valid_set.dat', \"rb\") as validation_file:\n",
    "    validation_set_data = pickle.load(validation_file)\n",
    "validation_set_data=validation_set_data[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_to_expected_input(dataset: List[Tuple[ np.ndarray, np.ndarray]]) -> Tuple[\n",
    "     np.ndarray, np.ndarray]:\n",
    "    x0_list = []\n",
    "    x1_list = []\n",
    "    for i in range(0, len(dataset)):\n",
    "        x0_list.append(dataset[i][0])\n",
    "        x1_list.append(dataset[i][1])\n",
    "    return (np.stack(x0_list), np.stack(x1_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChalearnDataset(Dataset):\n",
    "    def __init__(self,imagedata,tagdata,transform=None):\n",
    "        self.imagedata=imagedata\n",
    "        self.tagdata=tagdata\n",
    "        self.transform = transform  \n",
    "    def __len__(self):\n",
    "        return len(self.imagedata)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        image_data=self.imagedata[idx]\n",
    "        image_data=torch.FloatTensor(image_data)\n",
    "        image_data=image_data.permute(0,3,1,2)\n",
    "        big_five_sorces=self.tagdata[idx]\n",
    "        big_five_sorces = torch.FloatTensor(big_five_sorces)\n",
    "        return image_data,big_five_sorces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.debug('=============InceptionV2Train Strat!=============')\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "print(USE_CUDA)\n",
    "\n",
    "device = torch.device('cuda:0' if USE_CUDA else 'cpu')\n",
    "print('학습을 진행하는 기기:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsz = 5\n",
    "num_workerssz = 5\n",
    "lr = 0.001\n",
    "epochs = 32\n",
    "resnet_out_size = 512\n",
    "lstm_input_size = resnet_out_size\n",
    "lstm_hidden_size = 256\n",
    "lstm_num_layers = 2\n",
    "lstm_output_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_datas = reshape_to_expected_input(train_set_data)\n",
    "val_set_datas = reshape_to_expected_input(validation_set_data)\n",
    "train_dataset = ChalearnDataset(imagedata=train_set_datas[0],tagdata=train_set_datas[1],transform=transform)\n",
    "val_dataset = ChalearnDataset(imagedata=val_set_datas[0],tagdata=val_set_datas[1],transform=transform)\n",
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size=batchsz, shuffle=True, num_workers=num_workerssz)\n",
    "val_dataloader = DataLoader(dataset=val_dataset, batch_size=batchsz, shuffle=True, num_workers=num_workerssz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=VGG16.oneVGG16_0()\n",
    "# model=ResNet101.resnet101(num_classes=5)\n",
    "# model = Inception_V2.InceptionV2_0()\n",
    "# model = Inception_V2_LSTM.inceptionv2_LSTM()\n",
    "# model = VGG16_LSTM.VGG16_LSTM()\n",
    "# model = ResNet101_LSTM.ResNetLSTM(resnet_out_size=resnet_out_size, lstm_input_size=lstm_input_size, lstm_hidden_size=lstm_hidden_size, lstm_num_layers=lstm_num_layers, lstm_output_size=lstm_output_size)\n",
    "model.to(device)\n",
    "criterion = torch.nn.L1Loss().to(device) \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch = 0\n",
    "test_flage=False\n",
    "if test_flage==True:\n",
    "    checkpoint=torch.load(save_model_file_path.format('model',start_epoch,'pth'))\n",
    "    model.load_state_dict(checkpoint[\"model\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.cuda.device(0):\n",
    "    for i in range(epochs):\n",
    "        train_avg_loss = 0\n",
    "        val_avg_loss = 0\n",
    "        for image_data, big_five_data in tqdm(train_dataloader):\n",
    "            image_data = image_data.to(device)\n",
    "            big_five_data=big_five_data.permute(0,2,1)\n",
    "            big_five_data=big_five_data.squeeze()\n",
    "            big_five_data=big_five_data.to(device)\n",
    "            optimizer.zero_grad()  \n",
    "            hypothesis = model(image_data)  \n",
    "            loss = criterion(hypothesis, big_five_data)  \n",
    "            loss.backward()  \n",
    "            optimizer.step()  \n",
    "            train_avg_loss += loss  \n",
    "        train_avg_loss=train_avg_loss/len(train_dataloader)\n",
    "        with torch.no_grad():\n",
    "            for image_data, big_five_data in tqdm(val_dataloader):\n",
    "                image_data = image_data.to(device)\n",
    "                big_five_data=big_five_data.permute(0,2,1)\n",
    "                big_five_data=big_five_data.squeeze()\n",
    "                big_five_data=big_five_data.to(device)\n",
    "                hypothesis = model(image_data)\n",
    "                val_loss = criterion(hypothesis, big_five_data)\n",
    "                val_avg_loss += val_loss\n",
    "            val_avg_loss=val_avg_loss/len(val_dataloader)\n",
    "        torch.cuda.empty_cache()\n",
    "        max_value=val_avg_loss\n",
    "        start_epoch+=1\n",
    "        if (i + 1) % 5 == 0:\n",
    "            torch.save({\n",
    "                    'epoch': i+1,\n",
    "                    'model': model.state_dict(),\n",
    "                    'optimizer': optimizer.state_dict(),\n",
    "                    'loss': val_avg_loss,\n",
    "                }, save_model_file_path.format('model',start_epoch,'pth'))\n",
    "        logger.debug('Epoch: {} , 1-MAE: {:.4f} , train_loss:{:.4f} , val_loss:{:.4f} , MAX Value:{:.4f} , MAX Value Epoch:{}'.format(i+1, 1-val_avg_loss, train_avg_loss, val_avg_loss, max_value, start_epoch))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
